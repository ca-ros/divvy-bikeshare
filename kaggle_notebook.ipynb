{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af80824b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.004511,
     "end_time": "2022-07-04T06:53:18.135402",
     "exception": false,
     "start_time": "2022-07-04T06:53:18.130891",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Wrangling\n",
    "\n",
    "Data sources:\n",
    "- [Divvy bikes](https://divvybikes.com), download the raw data-sets [here](https://divvy-tripdata.s3.amazonaws.com/index.html)\n",
    "- [Chicago Data Portal](https://data.cityofchicago.org/), download the raw stations-table:\n",
    "  - Download the updated version [here](https://data.cityofchicago.org/Transportation/Divvy-Bicycle-Stations/bbyy-e7gq).\n",
    "  - Download the version I used [here](). June 28, 2022\n",
    "\n",
    "> The Stations table continues to get updates. I noticed some changes since I downloaded the data on May 15, 2022 and redownload on June 28, 2022. When I check the site, there is an update on May 18, 2022 hence the change in data.\n",
    "\n",
    "<sub>Tools used:</sub>\n",
    "- *PostgreSQL*\n",
    "- *RStudio*\n",
    "\n",
    "<details><summary>Skills applied</summary>\n",
    "<p>\n",
    "\n",
    "- Git - version control\n",
    "- Excel\n",
    "\n",
    "  - Conditional Formatting\n",
    "  - Data filter\n",
    "  - VLOOKUP\n",
    "  - Pivot table\n",
    "  - IF/ IFNA\n",
    "- SQL \n",
    "\n",
    "  - CREATE TABLE\n",
    "  - CREATE DB\n",
    "  - SELECT DISTINCT\n",
    "  - UPDATE TABLE\n",
    "  - HAVING\n",
    "  - LIKE\n",
    "  - WILDCARDS\n",
    "  - ALTER TABLE/ ALTER COLUMN\n",
    "  - IN\n",
    "  - CASE\n",
    "  - CAST\n",
    "  - EXTRACT: YEAR, EPOCH\n",
    "  - JOINS\n",
    "  - UNION\n",
    "  - SUB QUERY\n",
    "  - ROUND (percentage)\n",
    "- R\n",
    "\n",
    "  -\n",
    "  -\n",
    "  -\n",
    "  -\n",
    "  -\n",
    "- googling hard hehe\n",
    "</p></details>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "I. [Setting up SQL Environment](https://github.com/56i8/divvy-bikeshare/tree/master/documentations#setting-up-sql-environment)\n",
    "\n",
    "II. [Combining Data](https://github.com/56i8/divvy-bikeshare/tree/master/documentations#combining-data)\n",
    "\n",
    "- [2013](https://github.com/56i8/divvy-bikeshare/tree/master/documentations#2013)\n",
    "- [2014](https://github.com/56i8/divvy-bikeshare/tree/master/documentations#2014)\n",
    "- [2015](https://github.com/56i8/divvy-bikeshare/tree/master/documentations#2015)\n",
    "- [2016](https://github.com/56i8/divvy-bikeshare/tree/master/documentations#2016)\n",
    "- [2017](https://github.com/56i8/divvy-bikeshare/tree/master/documentations#2017)\n",
    "- [2018](https://github.com/56i8/divvy-bikeshare/tree/master/documentations#2018)\n",
    "- [2019](https://github.com/56i8/divvy-bikeshare/tree/master/documentations#2019)\n",
    "- [2020](https://github.com/56i8/divvy-bikeshare/tree/master/documentations#2020)\n",
    "- [2021](https://github.com/56i8/divvy-bikeshare/tree/master/documentations#2021)\n",
    "\n",
    "III. [Trips table](https://github.com/56i8/divvy-bikeshare/tree/master/documentations#trips-table)\n",
    "\n",
    "- [First table: trips_p1](https://github.com/56i8/divvy-bikeshare/tree/master/documentations#first-table-trips_p1)\n",
    "- [Second table: trips_p2](https://github.com/56i8/divvy-bikeshare/tree/master/documentations#second-table-trips_p2)\n",
    "- [Combining tables: trips]()\n",
    "\n",
    "IV. [Stations table]()\n",
    "\n",
    "- [Cleaning]()\n",
    "\n",
    "\n",
    "## Setting up SQL Environment\n",
    "\n",
    "The SQL database that I used in this analysis is [PostgreSQL](https://www.postgresql.org) and I used [pgAdmin 4](https://www.pgadmin.org/download/) as the database tool.\n",
    "\n",
    "*PgAdmin 4* has a default schema named \"Public\", it can be seen under Servers > PostgreSQL 14 > Databases > postgres > Schemas > Public.\n",
    "\n",
    "We need to create another schema named \"bike_trips\" to compile all our files under it, instead in \"public\" schema. Follow the steps:\n",
    "\n",
    "1. *Right click* \"Schemas\".\n",
    "2. *Click* \"Create\".\n",
    "3. *Click* \"Schema\".\n",
    "4. On **Name**, enter \"bike_trips\".\n",
    "5. *Click* \"Save\".\n",
    "\n",
    "Lastly, to open the **Query Tool** press *ALT + SHIFT + Q*, or click the Query tool icon on the upper-left corner of pgAdmin.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<h2 align = \"center\">Combining data</h2>\n",
    "\n",
    "The process of combining all the data into one table as a yearly data and using the **File Naming Convention (FNC)**.\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Download all the data for year 2013 to 2021 [here](https://divvy-tripdata.s3.amazonaws.com/index.html).\n",
    "2. Download the stations data [here](https://data.cityofchicago.org/api/views/bbyy-e7gq/rows.csv?accessType=DOWNLOAD), this data is from [Chicago Data Portal](https://data.cityofchicago.org/). For this analysis, I will refer to the table as **Stations table**.\n",
    "3. After extracting the zip files, compile separately all the yearly bike-trips data and the stations data included in that folder. Name the folder as the year it represents.\n",
    "4. Start compiling the data.\n",
    "5. For file naming convention, all combined trip-data must named by \"year\" followed by \"-divvy-tripdata.csv\"\n",
    "\n",
    "*Using RStudio*\n",
    "```r\n",
    "# load the necessary library\n",
    "\n",
    "install.library(tidyverse)\n",
    "library(tidyverse)\n",
    "```\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "### **2013**\n",
    "\n",
    "Rename the trip data \"Divvy-Trips_2013.csv\" to \"2013-divvy-tripdata.csv\"\n",
    "\n",
    "Import the csv file into the database.\n",
    "\n",
    "<sub>*PostgreSQL*</sub>\n",
    "```sql\n",
    "-- Create table\n",
    "CREATE TABLE bike_trips.trips_2013 (\n",
    "  trip_id bigint, \n",
    "  start_time timestamp without time zone, \n",
    "  end_time timestamp without time zone, \n",
    "  bike_id int, \n",
    "  trip_duration int, \n",
    "  start_station_id int, \n",
    "  start_station_name varchar(50), \n",
    "  end_station_id int, \n",
    "  end_station_name varchar(50), \n",
    "  user_type text, \n",
    "  gender text, \n",
    "  birth_year int);\n",
    "```\n",
    "\n",
    "```sql\n",
    "-- Import csv file\n",
    "COPY bike_trips.trips_2013 (\n",
    "  trip_id, \n",
    "  start_time, \n",
    "  end_time, \n",
    "  bike_id, \n",
    "  trip_duration, \n",
    "  start_station_id, \n",
    "  start_station_name, \n",
    "  end_station_id, \n",
    "  end_station_name, \n",
    "  user_type, \n",
    "  gender, \n",
    "  birth_year) \n",
    "FROM 'D:/Github/large csv files/divvy-bikeshare/trips/2013-divvy-tripdata.csv' \n",
    "DELIMITER ',' CSV HEADER;\n",
    "```\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<h3 align = \"center\"><strong>2014</strong></h3>\n",
    "\n",
    "<sub>*RStudio*</sub>\n",
    "\n",
    "```r\n",
    "# Merge 2014_tripdata\n",
    "df_2014 <- list.files(path=\"D:/Github/large csv files/divvy-bikeshare/trips/2014\", full.names = TRUE) %>% \n",
    "  lapply(read_csv) %>% \n",
    "  bind_rows \n",
    "```\n",
    "\n",
    "```r\n",
    "# Export the combined 2014_tripdata\n",
    "write.csv(df_2014,\"D:/Github/large csv files/divvy-bikeshare/trips/2014-divvy-tripdata.csv\", row.names = FALSE)\n",
    "```\n",
    "> Follow the file naming guideline, file name should be \"2014-divvy-tripdata.csv\".\n",
    "\n",
    "Import the csv file into the database.\n",
    "\n",
    "<sub>*PostgreSQL*</sub>\n",
    "```sql\n",
    "-- Create table\n",
    "CREATE TABLE bike_trips.trips_2014 (\n",
    "  trip_id bigint, \n",
    "  start_time timestamp without time zone, \n",
    "  end_time timestamp without time zone, \n",
    "  bike_id int, \n",
    "  trip_duration int, \n",
    "  start_station_id int, \n",
    "  start_station_name varchar(50), \n",
    "  end_station_id int, \n",
    "  end_station_name varchar(50), \n",
    "  user_type text, \n",
    "  gender text, \n",
    "  birth_year int);\n",
    "```\n",
    "\n",
    "```sql\n",
    "-- Import csv file\n",
    "COPY bike_trips.trips_2014 (\n",
    "  trip_id, \n",
    "  start_time, \n",
    "  end_time, \n",
    "  bike_id, \n",
    "  trip_duration, \n",
    "  start_station_id, \n",
    "  start_station_name, \n",
    "  end_station_id, \n",
    "  end_station_name, \n",
    "  user_type, \n",
    "  gender, \n",
    "  birth_year) \n",
    "FROM 'D:/Github/large csv files/divvy-bikeshare/trips/2014-divvy-tripdata.csv' \n",
    "DELIMITER ',' CSV HEADER QUOTE '\"' NULL 'NA';\n",
    "```\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<h3 align = \"center\"><strong>2015</strong></h3>\n",
    "\n",
    "<sub>*RStudio*</sub>\n",
    "\n",
    "```r\n",
    "# Merge 2015_tripdata\n",
    "df_2015 <- list.files(path=\"D:/Github/large csv files/divvy-bikeshare/trips/2015\", full.names = TRUE) %>% \n",
    "  lapply(read_csv) %>% \n",
    "  bind_rows \n",
    "```\n",
    "\n",
    "```r\n",
    "# Export the combined 2015_tripdata\n",
    "write.csv(df_2015,\"D:/Github/large csv files/divvy-bikeshare/trips/2015-divvy-tripdata.csv\", row.names = FALSE)\n",
    "```\n",
    "> Follow the file naming guideline, file name should be \"2015-divvy-tripdata.csv\".\n",
    "\n",
    "Import the csv file into the database.\n",
    "\n",
    "<sub>*PostgreSQL*</sub>\n",
    "```sql\n",
    "-- Create table\n",
    "CREATE TABLE bike_trips.trips_2015 (\n",
    "  trip_id bigint, \n",
    "  start_time timestamp without time zone, \n",
    "  end_time timestamp without time zone, \n",
    "  bike_id int, \n",
    "  trip_duration int, \n",
    "  start_station_id int, \n",
    "  start_station_name varchar(50), \n",
    "  end_station_id int, \n",
    "  end_station_name varchar(50), \n",
    "  user_type text, \n",
    "  gender text, \n",
    "  birth_year int);\n",
    "```\n",
    "\n",
    "```sql\n",
    "-- Import csv file\n",
    "COPY bike_trips.trips_2015 (\n",
    "  trip_id, \n",
    "  start_time, \n",
    "  end_time, \n",
    "  bike_id, \n",
    "  trip_duration, \n",
    "  start_station_id, \n",
    "  start_station_name, \n",
    "  end_station_id, \n",
    "  end_station_name, \n",
    "  user_type, \n",
    "  gender, \n",
    "  birth_year) \n",
    "FROM 'D:/Github/large csv files/divvy-bikeshare/trips/2015-divvy-tripdata.csv' \n",
    "DELIMITER ',' CSV HEADER QUOTE '\"' NULL 'NA';\n",
    "```\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<h3 align = \"center\"><strong>2016</strong></h3>\n",
    "\n",
    "<sub>*RStudio*</sub>\n",
    "\n",
    "```r\n",
    "# Merge 2016_tripdata\n",
    "df_2016 <- list.files(path=\"D:/Github/large csv files/divvy-bikeshare/trips/2016\", full.names = TRUE) %>% \n",
    "  lapply(read_csv) %>% \n",
    "  bind_rows \n",
    "```\n",
    "\n",
    "```r\n",
    "# Export the combined 2016_tripdata\n",
    "write.csv(df_2016,\"D:/Github/large csv files/divvy-bikeshare/trips/2016-divvy-tripdata.csv\", row.names = FALSE)\n",
    "```\n",
    "> Follow the file naming guideline, file name should be \"2016-divvy-tripdata.csv\".\n",
    "\n",
    "Import the csv file into the database.\n",
    "\n",
    "<sub>*PostgreSQL*</sub>\n",
    "```sql\n",
    "-- Create table\n",
    "CREATE TABLE bike_trips.trips_2016 (\n",
    "  trip_id bigint, \n",
    "  start_time timestamp without time zone, \n",
    "  end_time timestamp without time zone, \n",
    "  bike_id int, \n",
    "  trip_duration int, \n",
    "  start_station_id int, \n",
    "  start_station_name varchar(50), \n",
    "  end_station_id int, \n",
    "  end_station_name varchar(50), \n",
    "  user_type text, \n",
    "  gender text, \n",
    "  birth_year int);\n",
    "  ```\n",
    "\n",
    "```sql\n",
    "-- Import csv file\n",
    "COPY bike_trips.trips_2016 (\n",
    "  trip_id, \n",
    "  start_time, \n",
    "  end_time, \n",
    "  bike_id, \n",
    "  trip_duration, \n",
    "  start_station_id, \n",
    "  start_station_name, \n",
    "  end_station_id, \n",
    "  end_station_name, \n",
    "  user_type, \n",
    "  gender, \n",
    "  birth_year) \n",
    "FROM 'D:/Github/large csv files/divvy-bikeshare/trips/2016-divvy-tripdata.csv' \n",
    "DELIMITER ',' CSV HEADER QUOTE '\"' NULL 'NA';\n",
    "```\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<h3 align = \"center\"><strong>2017</strong></h3>\n",
    "\n",
    "<sub>*RStudio*</sub>\n",
    "\n",
    "```r\n",
    "# Merge 2017_tripdata\n",
    "df_2017 <- list.files(path=\"D:/Github/large csv files/divvy-bikeshare/trips/2017\", full.names = TRUE) %>% \n",
    "  lapply(read_csv) %>% \n",
    "  bind_rows \n",
    "```\n",
    "\n",
    "```r\n",
    "# Export the combined 2017_tripdata\n",
    "write.csv(df_2017,\"D:/Github/large csv files/divvy-bikeshare/trips/2017-divvy-tripdata.csv\", row.names = FALSE)\n",
    "```\n",
    "> Follow the file naming guideline, file name should be \"2017-divvy-tripdata.csv\".\n",
    "\n",
    "Import the csv file into the database.\n",
    "\n",
    "<sub>*PostgreSQL*</sub>\n",
    "```sql\n",
    "-- Create table\n",
    "CREATE TABLE bike_trips.trips_2017 (\n",
    "  trip_id bigint, \n",
    "  start_time timestamp without time zone, \n",
    "  end_time timestamp without time zone, \n",
    "  bike_id int, \n",
    "  trip_duration int, \n",
    "  start_station_id int, \n",
    "  start_station_name varchar(50), \n",
    "  end_station_id int, \n",
    "  end_station_name varchar(50), \n",
    "  user_type text, \n",
    "  gender text, \n",
    "  birth_year int);\n",
    "```\n",
    "\n",
    "```sql\n",
    "-- Import csv file\n",
    "COPY bike_trips.trips_2017 (\n",
    "  trip_id, \n",
    "  start_time, \n",
    "  end_time, \n",
    "  bike_id, \n",
    "  trip_duration, \n",
    "  start_station_id, \n",
    "  start_station_name, \n",
    "  end_station_id, \n",
    "  end_station_name, \n",
    "  user_type, \n",
    "  gender, \n",
    "  birth_year) \n",
    "FROM 'D:/Github/large csv files/divvy-bikeshare/trips/2017-divvy-tripdata.csv' \n",
    "DELIMITER ',' CSV HEADER QUOTE '\"' NULL 'NA';\n",
    "```\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<h3 align = \"center\"><strong>2018</strong></h3>\n",
    "\n",
    "<sub>*RStudio*</sub>\n",
    "\n",
    "```r\n",
    "# Merge 2018_tripdata\n",
    "df_2018 <- list.files(path=\"D:/Github/large csv files/divvy-bikeshare/trips/2018\", full.names = TRUE) %>% \n",
    "  lapply(read_csv) %>% \n",
    "  bind_rows \n",
    "```\n",
    "\n",
    "```r\n",
    "# Export the combined 2018_tripdata\n",
    "write.csv(df_2018,\"D:/Github/large csv files/divvy-bikeshare/trips/2018-divvy-tripdata.csv\", row.names = FALSE)\n",
    "```\n",
    "> Follow the file naming guideline, file name should be \"2018-divvy-tripdata.csv\".\n",
    "\n",
    "Import the csv file into the database.\n",
    "\n",
    "<sub>*PostgreSQL*</sub>\n",
    "```sql\n",
    "-- Create table\n",
    "CREATE TABLE bike_trips.trips_2018 (\n",
    "  trip_id bigint, \n",
    "  start_time timestamp without time zone, \n",
    "  end_time timestamp without time zone, \n",
    "  bike_id int, \n",
    "  trip_duration int, \n",
    "  start_station_id int, \n",
    "  start_station_name varchar(50), \n",
    "  end_station_id int, \n",
    "  end_station_name varchar(50), \n",
    "  user_type text, \n",
    "  gender text, \n",
    "  birth_year int);\n",
    "```\n",
    "\n",
    "```sql\n",
    "-- Import csv file\n",
    "COPY bike_trips.trips_2018 (\n",
    "  trip_id, \n",
    "  start_time, \n",
    "  end_time, \n",
    "  bike_id, \n",
    "  trip_duration, \n",
    "  start_station_id, \n",
    "  start_station_name, \n",
    "  end_station_id, \n",
    "  end_station_name, \n",
    "  user_type, \n",
    "  gender, \n",
    "  birth_year) \n",
    "FROM 'D:/Github/large csv files/divvy-bikeshare/trips/2018-divvy-tripdata.csv' \n",
    "DELIMITER ',' CSV HEADER QUOTE '\"' NULL 'NA';\n",
    "```\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<h3 align = \"center\"><strong>2019</strong></h3>\n",
    "\n",
    "This data set has inconsistent column naming. By using [Notepad++](https://notepad-plus-plus.org/downloads/) to open large datasets, each quarterly files are opened and inspected. We can see that 2019_Q2 table has different column names than the other tables, which will affect the merging process of the csv files. 2019_Q2 column name was matched to the rest of the other quarterly tables.\n",
    "\n",
    "<sub>*RStudio*</sub>\n",
    "\n",
    "```r\n",
    "# Merge 2019_tripdata\n",
    "df_2019 <- list.files(path=\"D:/Github/large csv files/divvy-bikeshare/trips/2019\", full.names = TRUE) %>% \n",
    "  lapply(read_csv) %>% \n",
    "  bind_rows \n",
    "```\n",
    "\n",
    "```r\n",
    "# Export the combined 2019_tripdata\n",
    "write.csv(df_2019,\"D:/Github/large csv files/divvy-bikeshare/trips/2019-divvy-tripdata.csv\", row.names = FALSE)\n",
    "```\n",
    "> Follow the file naming guideline, file name should be \"2019-divvy-tripdata.csv\".\n",
    "\n",
    "Import the csv file into the database.\n",
    "\n",
    "<sub>*PostgreSQL*</sub>\n",
    "```sql\n",
    "-- Create table\n",
    "CREATE TABLE bike_trips.trips_2019 (\n",
    "  trip_id bigint, \n",
    "  start_time timestamp without time zone, \n",
    "  end_time timestamp without time zone, \n",
    "  bike_id int, \n",
    "  trip_duration int, \n",
    "  start_station_id int, \n",
    "  start_station_name varchar(50), \n",
    "  end_station_id int, \n",
    "  end_station_name varchar(50), \n",
    "  user_type text, \n",
    "  gender text, \n",
    "  birth_year int);\n",
    "```\n",
    "\n",
    "```sql\n",
    "-- Import csv file\n",
    "COPY bike_trips.trips_2019 (\n",
    "  trip_id, \n",
    "  start_time, \n",
    "  end_time, \n",
    "  bike_id, \n",
    "  trip_duration, \n",
    "  start_station_id, \n",
    "  start_station_name, \n",
    "  end_station_id, \n",
    "  end_station_name, \n",
    "  user_type, \n",
    "  gender, \n",
    "  birth_year) \n",
    "FROM 'D:/Github/large csv files/divvy-bikeshare/trips/2019-divvy-tripdata.csv' \n",
    "DELIMITER ',' CSV HEADER QUOTE '\"' NULL 'NA';\n",
    "```\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<h3 align = \"center\"><strong>2020</strong></h3>\n",
    "\n",
    "<sub>*RStudio*</sub>\n",
    "\n",
    "```r\n",
    "# Merge 2020_tripdata\n",
    "df_2020 <- list.files(path=\"D:/Github/large csv files/divvy-bikeshare/trips/2020\", full.names = TRUE) %>% \n",
    "  lapply(read_csv) %>% \n",
    "  bind_rows \n",
    "```\n",
    "\n",
    "```r\n",
    "# Export the combined 2020_tripdata\n",
    "write.csv(df_2020,\"D:/Github/large csv files/divvy-bikeshare/trips/2020-divvy-tripdata.csv\", row.names = FALSE)\n",
    "```\n",
    "> Follow the file naming guideline, file name should be \"2020-divvy-tripdata.csv\".\n",
    "\n",
    "Import the csv file into the database.\n",
    "\n",
    "<sub>*PostgreSQL*</sub>\n",
    "```sql\n",
    "-- Create table\n",
    "CREATE TABLE bike_trips.trips_2020 (\n",
    "  trip_id bigint, \n",
    "  start_time timestamp without time zone, \n",
    "  end_time timestamp without time zone, \n",
    "  bike_id int, \n",
    "  trip_duration int, \n",
    "  start_station_id int, \n",
    "  start_station_name varchar(50), \n",
    "  end_station_id int, \n",
    "  end_station_name varchar(50), \n",
    "  user_type text, \n",
    "  gender text, \n",
    "  birth_year int);\n",
    "```\n",
    "\n",
    "```sql\n",
    "-- Import csv file\n",
    "COPY bike_trips.trips_2020 (\n",
    "  trip_id, \n",
    "  start_time, \n",
    "  end_time, \n",
    "  bike_id, \n",
    "  trip_duration, \n",
    "  start_station_id, \n",
    "  start_station_name, \n",
    "  end_station_id, \n",
    "  end_station_name, \n",
    "  user_type, \n",
    "  gender, \n",
    "  birth_year) \n",
    "FROM 'D:/Github/large csv files/divvy-bikeshare/trips/2020-divvy-tripdata.csv' \n",
    "DELIMITER ',' CSV HEADER QUOTE '\"' NULL 'NA';\n",
    "```\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<h3 align = \"center\"><strong>2021</strong></h3>\n",
    "\n",
    "<sub>*RStudio*</sub>\n",
    "\n",
    "```r\n",
    "# Merge 2021_tripdata\n",
    "df_2021 <- list.files(path=\"D:/Github/large csv files/divvy-bikeshare/trips/2021\", full.names = TRUE) %>% \n",
    "  lapply(read_csv) %>% \n",
    "  bind_rows \n",
    "```\n",
    "\n",
    "```r\n",
    "# Export the combined 2021_tripdata\n",
    "write.csv(df_2021,\"D:/Github/large csv files/divvy-bikeshare/trips/2021-divvy-tripdata.csv\", row.names = FALSE)\n",
    "```\n",
    "> Follow the file naming guideline, file name should be \"2021-divvy-tripdata.csv\".\n",
    "\n",
    "Import the csv file into the database.\n",
    "\n",
    "<sub>*PostgreSQL*</sub>\n",
    "```sql\n",
    "-- Create table\n",
    "CREATE TABLE bike_trips.trips_2021 (\n",
    "  trip_id bigint, \n",
    "  start_time timestamp without time zone, \n",
    "  end_time timestamp without time zone, \n",
    "  bike_id int, \n",
    "  trip_duration int, \n",
    "  start_station_id int, \n",
    "  start_station_name varchar(50), \n",
    "  end_station_id int, \n",
    "  end_station_name varchar(50), \n",
    "  user_type text, \n",
    "  gender text, \n",
    "  birth_year int);\n",
    "```\n",
    "\n",
    "```sql\n",
    "-- Import csv file\n",
    "COPY bike_trips.trips_2021 (\n",
    "  trip_id, \n",
    "  start_time, \n",
    "  end_time, \n",
    "  bike_id, \n",
    "  trip_duration, \n",
    "  start_station_id, \n",
    "  start_station_name, \n",
    "  end_station_id, \n",
    "  end_station_name, \n",
    "  user_type, \n",
    "  gender, \n",
    "  birth_year) \n",
    "FROM 'D:/Github/large csv files/divvy-bikeshare/trips/2021-divvy-tripdata.csv' \n",
    "DELIMITER ',' CSV HEADER QUOTE '\"' NULL 'NA';\n",
    "```\n",
    "\n",
    "Upon checking the structure of the tables in each year, we can notice that 2013-2019 have same data structure, while 2020-2021 have a different type of structure.\n",
    "\n",
    "Since the type of data from year 2020-2021 is different; where the station_ids are varchar instead of bigint and tables have an additional columns for stations' latitude and longitude, we will compile the two range of years separately.\n",
    "\n",
    "Combine all the trips from year 2020-2021, and do the same for year 2020-2021.\n",
    "\n",
    "> I named the year 2013-2019 table as trips_p1, and 2020-2021 table as trips_p2.\n",
    "\n",
    "trips_p1\n",
    "```sql\n",
    "CREATE TABLE AS bike_trips.trips_p1\n",
    "  SELECT * FROM bike_trips.trips_2013\n",
    "  UNION ALL\n",
    "  SELECT * FROM bike_trips.trips_2014\n",
    "  UNION ALL\n",
    "  SELECT * FROM bike_trips.trips_2015\n",
    "  UNION ALL\n",
    "  SELECT * FROM bike_trips.trips_2016\n",
    "  UNION ALL\n",
    "  SELECT * FROM bike_trips.trips_2017\n",
    "  UNION ALL\n",
    "  SELECT * FROM bike_trips.trips_2018\n",
    "  UNION ALL\n",
    "  SELECT * FROM bike_trips.trips_2019;\n",
    "```\n",
    "\n",
    "trips_p2\n",
    "```sql\n",
    "CREATE TABLE AS bike_trips.trips_p2\n",
    "  SELECT * FROM bike_trips.trips_2020\n",
    "  UNION ALL\n",
    "  SELECT * FROM bike_trips.trips_2021;\n",
    "```\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<h2 align = \"center\">Trips table</h2>\n",
    "\n",
    "The process of cleaning station names and station IDs in trips table, by verifying and matching the data available in Google Maps and Stations table.\n",
    "\n",
    "We need to import the **Stations** table to serve as a reference for our cleaning proces. But, before importing the file we need to make some changes:\n",
    "\n",
    "Steps:\n",
    "1. **Open Excel**: *Under Data* > *Get & Transform Data* > *Get Data* > *From File* > *From Text/CSV* > locate and import [Divvy_Bicycle_Stations.csv](). Under *Data Type Detection* select *Do not detect data types* and click **Load**. Delete **Sheet1**.\n",
    "2. **Remove row1**: Under *Table Design* > *Tools* > click *Convert to Range*, select **OK**. Then delete row1 which contains column#.\n",
    "3. **Freeze the header row/ top row**: Under *View* > *Window* > *Freeze Panes* > *Freeze Top Row*.\n",
    "4. **Delete duplicate stations**: Use conditional formatting on ColumnB (Station Name) to easily identify duplicate values. Under *Home* > *Styles* > *Conditional Formatting* > *Highlight Cell Rules* > *Duplicate Values*.\n",
    "5. Sort sheet by **Station Name** and look for duplicate values. Delete the record which has larger station ID. Then proceed to the next process.\n",
    "6. By using **Find and Replace**, remove all the parenthesis on **coordinates** column. Find \"(\" or \")\" then leave the *Replace with* field as blank. Do it for both open and close parenthesis.\n",
    "7. **Remove column**: **Docks in Service**\n",
    "8. Change the values under **Status** column: Not in Service = No, In Service = Yes.\n",
    "9. **Rename columns**: Station Name = **name**, Total Docks = **docks**, Status = **in_service**, and Location = **coordinate**.\n",
    "12. Save as [Stations.csv]().\n",
    "\n",
    "*Import csv file*\n",
    "\n",
    "```sql\n",
    "-- Create table\n",
    "CREATE TABLE bike_trips.stations (\n",
    "  id bigint,\n",
    "  name varchar,\n",
    "  docks int,\n",
    "  in_service text,\n",
    "  latitude numeric,\n",
    "  longitude numeric,\n",
    "  coordinate point);\n",
    "```\n",
    "\n",
    "```sql\n",
    "-- Import csv file\n",
    "COPY bike_trips.stations (\n",
    "  id,\n",
    "  name,\n",
    "  docks,\n",
    "  in_service,\n",
    "  latitude,\n",
    "  longitude,\n",
    "  coordinate)\n",
    "FROM 'D:/Github/divvy-bikeshare/csv files/stations/Stations.csv'\n",
    "DELIMITER ',' CSV HEADER;\n",
    "```\n",
    "\n",
    "> P.S. You can open normally the csv file using Excel but it will mess-up the station IDs.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<h3 align = \"center\"><strong>First table: trips_p1</strong></h3>\n",
    "\n",
    "Run a query to find all the missing/ mismatch station names and IDs to the **Stations** table. This includes columns *start_station_name*, *end_station_name*, *start_station_id* and *end_station_id*.\n",
    "\n",
    "```sql\n",
    "-- stations in trips_p1 where not in Stations table, 2013-2019\n",
    "-- check the data\n",
    "\n",
    "SELECT t.id, t.name\n",
    "FROM (\n",
    "  SELECT DISTINCT start_station_id as id, start_station_name as name \n",
    "  FROM bike_trips.trips_p1\n",
    "  UNION\n",
    "  SELECT DISTINCT end_station_id as id, end_station_name as name\n",
    "  FROM bike_trips.trips_p1) as t\n",
    "WHERE NOT EXISTS (\n",
    "  SELECT id, name\n",
    "  FROM bike_trips.stations as s\n",
    "  WHERE s.id = t.id)\n",
    "UNION\n",
    "SELECT t.id, t.name\n",
    "FROM (\n",
    "  SELECT DISTINCT start_station_name as name, start_station_id as id\n",
    "  FROM bike_trips.trips_p1\n",
    "  UNION\n",
    "  SELECT DISTINCT end_station_name as name, end_station_id as id\n",
    "  FROM bike_trips.trips_p1) as t\n",
    "WHERE NOT EXISTS (\n",
    "  SELECT id, name\n",
    "  FROM bike_trips.stations as s\n",
    "  WHERE s.name = t.name);\n",
    "\n",
    "-- 163 records\n",
    "```\n",
    "\n",
    "Export the result as [trips_p1_stations.csv]().\n",
    "\n",
    "In order to analyze the table, the following is done.\n",
    "\n",
    "<h4><strong>Process</strong>:</h4>\n",
    "\n",
    "1. Open the csv file using MS Excel. Rename columns: **id = old_id** & **name = old_name**.\n",
    "2. Create a new header for column C: **new_id**, column D: **new_name**, and column E: **changes**.\n",
    "3. **Import the Stations table**: Under *Data* > *Get & Transform Data* > *Get Data* > *From File* > *From Text/CSV* > locate [Stations.csv](). Under *Data Type Detection*, select *Do not detect data types* and click **Load**.\n",
    "4. **Remove row1**: Under *Table Design* > *Tools* > click **Convert to Range**, select **OK**. Then delete row1 which contains column#.\n",
    "5. Copy column **id** to the right of column **name**. *Right Click* column C and select Insert, a new empty column C should appear. Copy ColumnA to ColumnC.\n",
    "6. **Freeze the header row/ top row**: Under *View* > *Window* > *Freeze Panes* > *Freeze Top Row*. Do the same for the other sheet.\n",
    "7. In **trips_p1_stations** sheet:\n",
    "\n",
    "   - **Cell C2**: enter the formula `=IFNA(VLOOKUP(TEXT(B2,0),Stations!$B:$D,2,FALSE),\"same\")`, then press Enter. Click the cell again and double-click the *bottom-right* corner of the cell to copy the formula in the entire row.\n",
    "   - **Cell D2**: enter the formula `=IFNA(VLOOKUP(TEXT(A2,0),Stations!$A:$B,2,FALSE),\"same\")`, then press Enter. Click the cell again and double-click the *bottom-right* corner of the cell to copy the formula in the entire row.\n",
    "   - **Cell E2**: enter the formula `=IF(AND(D2=\"same\",C2=\"same\"),\"missing\",IF(B2=D2,\"same\",IF(AND(A2<>C2,D2=\"same\"),\"id\",IF(B2<>D2,\"name\"))))`, then press Enter. Click the cell again and double-click the *bottom-right* corner of the cell to copy the formula in the entire row.\n",
    "   \n",
    "8. **Use conditinal formatting**: Under *Home* > *Styles* > *Conditional Formatting* > *Highlight Cell Rules* > ...\n",
    "\n",
    "    - **Column C**: *Text that contains* > \"*same*\" with **Green Fill with Dark Green Text**.\n",
    "    - **Column D**: *Text that contains* > \"*same*\" with **Green Fill with Dark Green Text**.\n",
    "    - **Column E**: \n",
    "      - *Text that contains* > \"*missing*\" with **Light Red Fill with Dark Red Text**.\n",
    "      - *Text that contains* > \"*name*\" with **Yellow Fill with Dark Yellow Text**.\n",
    "      - *Text that contains* > \"*id*\" with **Green Fill with Dark Green Text**.\n",
    "      \n",
    "9. Validate the **new_name** column by searching each names in [Google Maps](https://www.google.com/maps) and locate nearby **divvy-stations**.\n",
    "\n",
    "    - **Example**:\n",
    "\n",
    "      <details><summary>Click Me!</summary>\n",
    "      <p>\n",
    "\n",
    "      ID = **17**, name = **Wood St & Division St**. Use [Google Maps](https://www.google.com/maps) to validate the station_name.\n",
    "\n",
    "      - Search Chicago to focus the search in Chicago City.\n",
    "\n",
    "      ![Chicago](https://snipboard.io/vYIsW9.jpg)\n",
    "\n",
    "      - Enter the station_name, **Wood St & Division St**, and *press Enter*.\n",
    "      - Click **Nearby** and search **divvy**, to search nearby divvy-bike stations.\n",
    "\n",
    "      ![17](https://snipboard.io/n4qvdG.jpg)\n",
    "\n",
    "      - Hover over to the nearest station to view the station name.\n",
    "\n",
    "      ![17.2](https://snipboard.io/LHBqnm.jpg)\n",
    "\n",
    "      The nearest station is **Honore St & Division St**.\n",
    "\n",
    "      > Upon checking the **Stations** table on ID number 17, we can confirm that station_id 17 is Honore St & Division St.\n",
    "\n",
    "      ![17 excel](https://snipboard.io/najrpI.jpg)\n",
    "\n",
    "      > Thus, **Wood St & Division St** is a wrong station name and must be replaced with correct name **Honore St & Division St**. You can also notice under **changes** column, it says **name**, which means **name change**.\n",
    "\n",
    "      ![sample excel](https://snipboard.io/ixN0TV.jpg)\n",
    "\n",
    "      </p>\n",
    "      </details>\n",
    "\n",
    "` `  \n",
    "\n",
    "10. **Create another table**: \n",
    "\n",
    "    - For **missing stations**: (24 records)\n",
    "      - Filter changes column with values **missing**. Copy columns **old_id** and **old_name** into a new blank workbook and save it as [missing_stations_p1.csv]().\n",
    "    - For **id changes**: (2 records)\n",
    "      - Filter changes column with values **id**. Copy columns **old_name** and **new_id** into a new blank workbook and save it as [id_changes_p1.csv]().\n",
    "    - For **name changes**: (137 records)\n",
    "      - Filter changes column with values **name**. Copy columns **old_name** and **new_name** into a new blank workbook and save it as [name_changes_p1.csv]().\n",
    "\n",
    "> **Optional**: You can hide error values indicators. Under *File* > *Options* > *Formulas* > *Error Checking* > uncheck *Enable background error checking*.\n",
    "\n",
    "> Upon checking, 2 station names from **trips_p1** table has already existing names in **Stations** table. Thus, duplicate station names with a different **station_id**.\n",
    "\n",
    "` `  \n",
    "\n",
    "Going back to PostgreSQL:\n",
    "\n",
    "Stations names **Lakefront Trail & Bryn Mawr Ave** and **Michigan Ave & 71st St** already have existing IDs in **Stations** table.\n",
    "\n",
    "Since the smaller station ID is not used in **Stations** table, I used it as a new station ID which are **459** and **651** for **Lakefront Trail & Bryn Mawr Ave** and **Michigan Ave & 71st St** respectively.\n",
    "\n",
    "**SQL Queries:**\n",
    "\n",
    "*Import csv file*\n",
    "\n",
    "- id_changes_p1.csv\n",
    "```sql\n",
    "CREATE TABLE bike_trips.id_changes_p1 (\n",
    "  old_name varchar, \n",
    "  new_id int);\n",
    "\n",
    "-- Import\n",
    "COPY bike_trips.id_changes_p1 (old_name, new_id)\n",
    "FROM 'D:/Github/divvy-bikeshare/csv files/stations/id_changes_p1.csv' \n",
    "DELIMITER ',' CSV HEADER;\n",
    "```\n",
    "\n",
    "- name_changes_p1.csv\n",
    "```sql\n",
    "-- Create table\n",
    "CREATE TABLE bike_trips.name_changes_p1 (\n",
    "  old_name varchar, \n",
    "  new_name varchar);\n",
    "\n",
    "-- Import\n",
    "COPY bike_trips.name_changes_p1 (old_name, new_name)\n",
    "FROM 'D:/Github/divvy-bikeshare/csv files/stations/name_changes_p1.csv' \n",
    "DELIMITER ',' CSV HEADER;\n",
    "```\n",
    "\n",
    "*ID change*\n",
    "\n",
    "- start_station_id\n",
    "```sql\n",
    "UPDATE bike_trips.trips_p1 as s\n",
    "SET start_station_id = c.new_id\n",
    "FROM bike_trips.id_changes_p1 as c\n",
    "WHERE s.start_station_name = c.old_name;\n",
    "```\n",
    "\n",
    "- end_station_id\n",
    "```sql\n",
    "UPDATE bike_trips.trips_p1 as s\n",
    "SET end_station_id = c.new_id\n",
    "FROM bike_trips.id_changes_p1 as c\n",
    "WHERE s.end_station_name = c.old_name;\n",
    "```\n",
    "\n",
    "*Name change*\n",
    "```sql\n",
    "-- start_station_name\n",
    "UPDATE bike_trips.trips_p1 as s\n",
    "SET start_station_name = c.new_name\n",
    "FROM bike_trips.name_changes_p1 as c\n",
    "WHERE s.start_station_name = c.old_name;\n",
    "```\n",
    "```sql\n",
    "-- end_station_name\n",
    "UPDATE bike_trips.trips_p1 as s\n",
    "SET end_station_name = c.new_name\n",
    "FROM bike_trips.name_changes_p1 as c\n",
    "WHERE s.end_station_name = c.old_name;\n",
    "```\n",
    "\n",
    "> P.S. After cleaning both tables, some data are added into **id_changes_p1.csv** & **name_changes_p1.csv**. Worry not since all the uploaded and linked files are updated.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<h3 align = \"center\"><strong>Second table: trips_p2</strong></h3>\n",
    "\n",
    "```sql\n",
    "-- stations in trips_p2 where not in Stations table, 2020-2021\n",
    "-- check the data\n",
    "SELECT t.id, t.name\n",
    "FROM (\n",
    "  SELECT DISTINCT start_station_id as id, start_station_name as name \n",
    "  FROM bike_trips.trips_p2\n",
    "  UNION\n",
    "  SELECT DISTINCT end_station_id as id, end_station_name as name \n",
    "  FROM bike_trips.trips_p2) as t\n",
    "WHERE NOT EXISTS (\n",
    "  SELECT id, name\n",
    "  FROM bike_trips.stations as s\n",
    "  WHERE CAST(s.id AS varchar) = t.id)\n",
    "UNION\n",
    "SELECT t.id, t.name\n",
    "FROM (\n",
    "  SELECT DISTINCT start_station_name as name, start_station_id as id \n",
    "  FROM bike_trips.trips_p2\n",
    "  UNION\n",
    "  SELECT DISTINCT end_station_name as name, end_station_id as id \n",
    "  FROM bike_trips.trips_p2)as t\n",
    "WHERE NOT EXISTS (\n",
    "  SELECT s.id, s.name\n",
    "  FROM bike_trips.stations as s\n",
    "  WHERE s.name = t.name);\n",
    "\n",
    "-- 716 records\n",
    "```\n",
    "Export the result as [trips_p2_stations.csv](https://github.com/56i8/divvy-bikeshare/blob/master/csv%20files/stations/trips_p2_stations.csv). \n",
    "\n",
    "**Process:**\n",
    "\n",
    "1. Open the csv file using MS Excel. Rename columns: **id = old_id** & **name = old_name**.\n",
    "2. Create a new header for column C: **new_id**, column D: **new_name** and column E: **changes**, and column F: **verified**.\n",
    "3. **Import the Stations table**: Under *Data* > *Get & Transform Data* > *Get Data* > *From File* > *From Text/CSV* > locate [Stations.csv](). Under *Data Type Detection* > select *Do not detect data types* and click **Load**.\n",
    "4. **Remove row1**: Under *Table Design* > *Tools* > click **Convert to Range**, select **OK**. Then delete row1 which contains column#.\n",
    "5. Copy column **id** to the right of column **name**. *Right Click* column C and select Insert, a new empty column C should appear. Copy ColumnA to ColumnC.\n",
    "6. **Freeze the header row/ top row**: Under *View* > *Window* > *Freeze Panes* > *Freeze Top Row*. Do the same for the other sheet.\n",
    "7. In **trips_p2_stations** sheet:\n",
    "\n",
    "    - **Cell C2**: enter the formula `=IFNA(VLOOKUP(TEXT(B2,0),Stations!$B:$D,2,FALSE),\"same\")`, then press Enter. Click the cell again and double-click the bottom-right corner of the cell to copy the formula in the entire row.\n",
    "    - **Cell D2**: enter the formula `=IFNA(VLOOKUP(TEXT(A2,0),Stations!$A:$B,2,FALSE),\"same\")`, then press Enter. Click the cell again and double-click the bottom-right corner of the cell to copy the formula in the entire row.\n",
    "    - **Cell E2**: enter the formula `=IF(C2 = \"\", \"missing\", IF(AND(D2=\"same\",C2=\"same\"),\"missing\",IF(B2=D2,\"same\",IF(AND(A2<>C2,D2=\"same\"),\"id\",IF(AND(B2<>D2,C2=\"same\"),\"name\",IF(AND(A2<>C2,B2<>D2),\"both\"))))))`, then press Enter. Click cell E2 again and double-click the bottom-right corner of the cell to copy the formula in the entire row.\n",
    "\n",
    "8. **Use conditinal formatting**: Under *Home* > *Styles* > *Conditional Formatting* > *Highlight Cell Rules* > ...\n",
    "\n",
    "    - **Column A**: *Duplicate Values*.\n",
    "    - **Column B**: *Duplicate Values*.\n",
    "    - **Column C**: *Text that contains* > \"*same*\" with **Green Fill with Dark Green Text**.\n",
    "    - **Column D**: *Text that contains* > \"*same*\" with **Green Fill with Dark Green Text**.\n",
    "    - **Column E**:\n",
    "      - *Text that contains* > \"*missing*\" with **Light Red Fill with Dark Red Text**.\n",
    "      - *Text that contains* > \"*name*\" with **Yellow Fill with Dark Yellow Text**.\n",
    "      - *Text that contains* > \"*id*\" with **Green Fill with Dark Green Text**.\n",
    "      - *Text that contains* > \"*both*\" with **Custom Format**. I used **Light Blue fill with Dark Blue Text**.\n",
    "    - **Column F**: *Text that contains* > \"*y*\" with **Green Fill with Dark Green Text**.\n",
    "9. Validate the **new_name** column by searching each names in [Google Maps](https://www.google.com/maps) and locate nearby **divvy-stations**.\n",
    "\n",
    "    <details><summary>Validating sample:</summary>\n",
    "    <p>\n",
    "\n",
    "    - station_id = 17\n",
    "    - Either a missing station_id **17** or station_name **Wood St & Division St**.\n",
    "\n",
    "    Using [Google Maps](https://www.google.com/maps) to validate the station_name.\n",
    "\n",
    "    - Search **Chicago** to focus the search in Chicago City.\n",
    "\n",
    "    ![Chicago](https://snipboard.io/vYIsW9.jpg)\n",
    "\n",
    "    - Enter the station_name, **Wood St & Division St**, and *press Enter*.\n",
    "    - Click **Nearby** and search **divvy**, to search nearby divvy-bike stations.\n",
    "\n",
    "    ![17](https://snipboard.io/n4qvdG.jpg)\n",
    "\n",
    "    - Hover over to the nearest station to view the station name.\n",
    "\n",
    "    ![17.2](https://snipboard.io/LHBqnm.jpg)\n",
    "\n",
    "    The nearest station is **Honore St & Division St**.\n",
    "\n",
    "    > Upon checking the **Stations** table on ID number 17, we can confirm that station_id 17 is Honore St & Division St.\n",
    "\n",
    "    ![17 excel](https://snipboard.io/najrpI.jpg)\n",
    "\n",
    "    > Thus, **Wood St & Division St** is a wrong station name and must be replaced with correct name **Honore St & Division St**. You can also notice under **changes** column, it says **name**, which means **name change**.\n",
    "\n",
    "    ![sample excel](https://snipboard.io/ixN0TV.jpg)\n",
    "\n",
    "    </p></details>\n",
    "\n",
    "` `  \n",
    "\n",
    "10. **Cleaning process**: aside from `VLOOKUP`, we will use **Find**, **Google Maps**, and manual process to match the data.\n",
    "\n",
    "    - **Example #1**: *Find*\n",
    "      1. Filter changes column by **missing** and sort the sheet by **old_name** in ascending order.\n",
    "      2. First row of **old_name** column is **Archer (Damen) Ave & 37th St** with ID = **18022**. Then, *Find* **Archer** in **Stations** sheet and click *Find all*.\n",
    "      3. Among the results, we can find **Archer Damen Ave & 37th St** with ID = **645**.\n",
    "      4. Go back to **trips_p2_stations** sheet. Replace the values in columns **new_id** and **new_name** with **645** and **Archer Damen Ave & 37th St** respectively.\n",
    "      5. Notice than value in **changes** column changed from **missing** to **both**, which means that data needs to change its **name** and **id**.\n",
    "      6. Put \"**y**\" in the **verified** column.\n",
    "\n",
    "    - **Example #2**: *Google Maps*\n",
    "      1. Filter changes column by **missing** and sort the sheet by **old_name** in ascending order.\n",
    "      2. Second row of **old_name** column is **Base - 2132 W Hubbard Warehouse** with ID = **Hubbard Bike-checking (LBS-WH-TEST)**. The station_id is **varchar** data type, so we need to confirm the station name. If you remember, in **missing_stations_p1.csv** there is a missing station that contains **Hubbard**.\n",
    "      3. Upon checking we can see ID = **671** and name = **HUBBARD ST BIKE CHECKING (LBS-WH-TEST)**. We should check if these two stations are the same by checking out its coordinate and locate it on **Google Maps**.\n",
    "      4. **Run a query**:\n",
    "          - Base - 2132 W Hubbard Warehouse\n",
    "          ```sql\n",
    "          SELECT start_lat, start_lng FROM bike_trips.trips_p2\n",
    "          WHERE start_station_name = 'Base - 2132 W Hubbard Warehouse'\n",
    "\n",
    "          /*\n",
    "          start_lat = 41.8899545160741\n",
    "          start_lng = -87.6806509494781\n",
    "          coordinate = 41.8899545160741, -87.6806509494781\n",
    "          */\n",
    "          ```\n",
    "\n",
    "          - HUBBARD ST BIKE CHECKING (LBS-WH-TEST)\n",
    "          ```sql\n",
    "          SELECT start_lat, start_lng FROM bike_trips.trips_p2\n",
    "          WHERE start_station_name = 'HUBBARD ST BIKE CHECKING (LBS-WH-TEST)'\n",
    "\n",
    "          /*\n",
    "          start_lat = 41.89\n",
    "          start_lng = -87.6807\n",
    "          coordinate = 41.89, -87.6807\n",
    "          */\n",
    "          ```\n",
    "\n",
    "      5. **Locate** both coordinates in Google Maps. \n",
    "\n",
    "      ![coordinate](https://snipboard.io/oHMIyk.jpg)\n",
    "\n",
    "      6. Both coordinates point at **Divvy Service Warehouse**. Therefore, change the name of both stations to **Divvy Service Warehouse** and use ID = **671**.\n",
    "      7. Put \"**y**\" in the **verified** column. \n",
    "\n",
    "    - **Example #3**: *Manual process*\n",
    "      1. Sort sheet by column **id** in ascending order and look for duplicate values.\n",
    "      2. On ID = **329**, we can see different records. One record has changes to **name** and the other has changes to **both**.\n",
    "\n",
    "      ![329](https://snipboard.io/4ZGcKj.jpg)\n",
    "\n",
    "      3. The station name **Central Park Ave & Douglas Blvd** is actually on the **Stations** table, its just the ID used in the **trips** table is different which creates a conflict with on station IDs. Therefore, we can change the value in **new_name** column by **same**.\n",
    "\n",
    "      ![329 cleaned](https://snipboard.io/AqMiYN.jpg)\n",
    "\n",
    "      4. Put \"**y**\" in the **verified** column.\n",
    "\n",
    "     \n",
    "11. **Create another table**: \n",
    "\n",
    "    - For **missing stations**:\n",
    "      - Filter changes column with values **missing**. Copy columns **old_id**, **old_name**, and **new_id** into a new blank workbook. Remove row14 where **old_id** and **old_name** is equal to **NULL**. Remove all values in **old_id** column except if it has a \"**same**\" value on **new_id** column. Delete **new_id** column and save it as [missing_stations_p2.csv]().\n",
    "    - For **id changes**:\n",
    "      - Filter changes column with values **id** and **both**. Copy columns **old_name** and **new_id** into a new blank workbook. Remove duplicates on **old_name** column and remove rows where values on **old_name** column = **NULL**. Save it as [id_changes_p2.csv]().\n",
    "    - For **name changes**:\n",
    "      - Filter changes column with values **name** and **both**. Copy columns **old_name** and **new_name** into a new blank workbook. Remove duplicates on **old_name** column and remove rows where values on **old_name** column = **NULL**. Save it as [name_changes_p2.csv]().\n",
    "\n",
    "\n",
    "> **Optional**: You can hide error values indicators. Under *File* > *Options* > *Formulas* > *Error Checking* > uncheck *Enable background error checking*.\n",
    "\n",
    "> Upon checking we can identify which names are duplicated, used a wrong station_id and missing from the official **Stations** table. By sorting the column by **id_status**, we can see that all the station_id in column A has a mixed types of data, *varchar* and *bigint*.\n",
    "\n",
    "> Some stations names have null values, data are filled after finding same station ID and vice-versa.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "**SQL Queries:**\n",
    "\n",
    "*Import csv files*\n",
    "\n",
    "- id_changes_p2.csv\n",
    "\n",
    "```sql\n",
    "-- Create table\n",
    "CREATE TABLE bike_trips.id_changes_p2 (\n",
    "  old_name varchar,\n",
    "  new_id bigint);\n",
    "\n",
    "-- Import\n",
    "COPY bike_trips.id_changes_p2 (old_name, new_id)\n",
    "FROM 'D:/Github/divvy-bikeshare/csv files/stations/id_changes_p2.csv' \n",
    "DELIMITER ',' CSV HEADER NULL 'null';\n",
    "```\n",
    "\n",
    "- name_changes_p2.csv\n",
    "\n",
    "```sql\n",
    "-- Create table\n",
    "CREATE TABLE bike_trips.name_changes_p2 (\n",
    "  old_name varchar,\n",
    "  new_name varchar);\n",
    "\n",
    "-- Import\n",
    "COPY bike_trips.name_changes_p2 (old_name, new_name)\n",
    "FROM 'D:/Github/divvy-bikeshare/csv files/stations/name_changes_p2.csv' \n",
    "DELIMITER ',' CSV HEADER NULL 'null';\n",
    "```\n",
    "\n",
    "*ID change*\n",
    "\n",
    "- start_station_id\n",
    "\n",
    "```sql\n",
    "UPDATE bike_trips.trips_p2\n",
    "SET start_station_id = CASE\n",
    "  WHEN start_station_id = 'WL-008' THEN '57'\n",
    "  WHEN start_station_id = '13221' THEN '61'\n",
    "  WHEN start_station_id = '20215' THEN '732'\n",
    "  END\n",
    "WHERE start_station_id IN ('WL-008', '13221', '20215');\n",
    "```\n",
    "```sql\n",
    "UPDATE bike_trips.trips_p2 as s\n",
    "SET start_station_id = CAST(c.new_id AS varchar)\n",
    "FROM bike_trips.id_changes_p2 as c\n",
    "WHERE s.start_station_name = c.old_name;\n",
    "```\n",
    "\n",
    "- end_station_id\n",
    "```sql\n",
    "UPDATE bike_trips.trips_p2\n",
    "SET end_station_id = CASE\n",
    "  WHEN end_station_id = 'WL-008' THEN '57'\n",
    "  WHEN end_station_id = '13221' THEN '61'\n",
    "  WHEN end_station_id = '20215' THEN '732'\n",
    "  END\n",
    "WHERE end_station_id IN ('WL-008', '13221', '20215');\n",
    "```\n",
    "```sql\n",
    "UPDATE bike_trips.trips_p2 as s\n",
    "SET end_station_id = CAST(c.new_id AS varchar)\n",
    "FROM bike_trips.id_changes_p2 as c\n",
    "WHERE s.end_station_name = c.old_name;\n",
    "```\n",
    "\n",
    "*Name change*\n",
    "CASE\n",
    "- start_station\n",
    "```sql\n",
    "UPDATE bike_trips.trips_p2\n",
    "SET start_station_name = CASE\n",
    "  WHEN start_station_id = '57' THEN 'Clinton St & Roosevelt Rd'\n",
    "  WHEN start_station_id = '61' THEN 'Wood St & Milwaukee Ave'\n",
    "  WHEN start_station_id = '732' THEN 'Hegewisch Metra Station'\n",
    "  END\n",
    "WHERE start_station_id IN ('57', '61', '732');\n",
    "```\n",
    "```sql\n",
    "UPDATE bike_trips.trips_p2 as s\n",
    "SET start_station_name = c.new_name\n",
    "FROM bike_trips.name_changes_p2 as c\n",
    "WHERE s.start_station_name = c.old_name;\n",
    "```\n",
    "\n",
    "- end_station\n",
    "```sql\n",
    "UPDATE bike_trips.trips_p2\n",
    "SET end_station_name = CASE\n",
    "  WHEN end_station_id = '57' THEN 'Clinton St & Roosevelt Rd'\n",
    "  WHEN end_station_id = '61' THEN 'Wood St & Milwaukee Ave'\n",
    "  WHEN end_station_id = '732' THEN 'Hegewisch Metra Station'\n",
    "  END\n",
    "WHERE end_station_id IN ('57', '61', '732');\n",
    "```\n",
    "```sql\n",
    "UPDATE bike_trips.trips_p2 as s\n",
    "SET end_station_name = c.new_name\n",
    "FROM bike_trips.name_changes_p2 as c\n",
    "WHERE s.end_station_name = c.old_name;\n",
    "```\n",
    "\n",
    "> P.S. After cleaning both tables, some data are added into **id_changes_p1.csv** & **name_changes_p1.csv**. Worry not since all the uploaded and linked files are updated.\n",
    "\n",
    "&nbsp;\n",
    "~\n",
    "<h3 align = \"center\"><strong>Combine table: trips</strong></h3>\n",
    "\n",
    "Before combining both tables, some changes has to be made first. By checking the schema of the tables we can see the differences in their data. After modifying, merge both tables into one and save as **trips** table.\n",
    "\n",
    "<h4><strong>Schema</strong></h4>\n",
    "\n",
    "*Table Columns*\n",
    "\n",
    "- trips_p1\n",
    "\n",
    "```\n",
    "| Field name         | Type                        |\n",
    "| ------------------ | --------------------------- |\n",
    "| trip_id            | bigint                      |\n",
    "| start_time         | timestamp without time zone |\n",
    "| end_time           | timestamp without time zone |\n",
    "| bike_id            | integer                     |\n",
    "| duration           | integer                     |\n",
    "| start_station_id   | integer                     |\n",
    "| start_station_name | character varying           |\n",
    "| end_station_id     | integer                     |\n",
    "| end_station_name   | character varying           |\n",
    "| user_type          | text                        |\n",
    "| gender             | text                        |\n",
    "| birth_year         | integer                     |\n",
    "```\n",
    "\n",
    "- trips_p2\n",
    "```\n",
    "| Field name         | Type                        |\n",
    "| ------------------ | --------------------------- |\n",
    "| ride_id            | character varying           |\n",
    "| rideable_type      | character varying           |\n",
    "| start_time         | timestamp without time zone |\n",
    "| end_time           | timestamp without time zone |\n",
    "| start_station_id   | character varying           |\n",
    "| start_station_name | character varying           |\n",
    "| end_station_id     | character varying           |\n",
    "| end_station_name   | character varying           |\n",
    "| start_lat          | numeric                     |\n",
    "| start_lng          | numeric                     |\n",
    "| end_lat            | numeric                     |\n",
    "| end_lng            | numeric                     |\n",
    "| user_type          | text                        |\n",
    "```\n",
    "\n",
    "**Table changes**:\n",
    "- *trips_p1*\n",
    "  - change data type of column **trip_id**: *bigint* to *varchar*.\n",
    "  - rename column: **trip_id** to **ride_id**\n",
    "- **trips_p2**\n",
    "  - remove columns: **start_lat**, **start_lng**, **end_lat** & **end_lng**.\n",
    "  - fill missing data: **duration** by using start_time and end_time.\n",
    "  - change data type of columns **start_station_id** & **end_station_id**: from *varchar* to *bigint*.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "**SQL Query:**\n",
    "\n",
    "```sql\n",
    "CREATE TABLE bike_trips.trips AS\n",
    "SELECT \n",
    "  CAST(trip_id AS varchar) AS ride_id,\n",
    "  CAST(null AS varchar) AS rideable_type,\n",
    "  bike_id,\n",
    "  start_time,\n",
    "  end_time,\n",
    "  trip_duration,\n",
    "  CAST(start_station_id AS bigint),\n",
    "  start_station_name,\n",
    "  CAST(end_station_id AS bigint),\n",
    "  end_station_name,\n",
    "  user_type,\n",
    "  gender,\n",
    "  birth_year\n",
    "FROM bike_trips.trips_p1\n",
    "UNION ALL\n",
    "SELECT\n",
    "  ride_id,\n",
    "  rideable_type,\n",
    "  CAST(null AS int) AS bike_id,\n",
    "  start_time,\n",
    "  end_time,\n",
    "  EXTRACT(EPOCH FROM(end_time - start_time))::int as trip_duration,\n",
    "  CAST(start_station_id AS bigint),\n",
    "  start_station_name,\n",
    "  CAST(end_station_id AS bigint),\n",
    "  end_station_name,\n",
    "  user_type,\n",
    "  CAST(null AS text) AS gender,\n",
    "  CAST(null AS int) AS birth_year\n",
    "FROM bike_trips.trips_p2;\n",
    "```\n",
    "\n",
    "**Data omitted**:\n",
    "\n",
    "Some data are omitted in table **trips_p2** that has NULL **station_names** & **station_id**. Although these records doesn't contain any data about its *station_names* and *station_IDs*, these have a coordinates which then can be used to identify the nearby **DIVVY** station name. The data will be filled in the future after finishing my studies on Webscraping in Python.\n",
    "\n",
    "*Number of records*\n",
    "```\n",
    "| Data     | No. of records |\n",
    "| -------- | -------------- |\n",
    "| trips_p1 |     24,426,783 |       \n",
    "| trips_p2 |      9,136,746 |\n",
    "| trips    |     33,563,529 |\n",
    "| NULL     |      1,158,190 |\n",
    "```\n",
    "\n",
    "*Percent of NULL values*\n",
    "```\n",
    "| Table    | NULL values |\n",
    "| -------- | ----------- |\n",
    "| trips_p1 |         0 % |\n",
    "| trips_p2 |     12.68 % |\n",
    "| trips    |      3.45 % |\n",
    "```\n",
    "\n",
    "Divvy-bikeshare dataset contains 3.45% of NULL values. Since the percentage is small, we can then omit these records and proceed with the analysis.\n",
    "\n",
    "&nbsp;    \n",
    "\n",
    "**SQL Queries**:\n",
    "\n",
    "*Number of records*\n",
    "```sql\n",
    "-- trips_p1: 24,426,783\n",
    "SELECT COUNT(*) FROM bike_trips.trips_p1;\n",
    "\n",
    "-- trips_p2: 9,136,746\n",
    "SELECT COUNT(*) FROM bike_trips.trips_p2;\n",
    "\n",
    "-- total: 33,563,529\n",
    "SELECT COUNT(*) FROM bike_trips.trips;\n",
    "\n",
    "-- total NULL records: 1,158,190\n",
    "SELECT CAST(COUNT(*) AS numeric) \n",
    "  FROM bike_trips.trips_p2\n",
    "  WHERE (start_station_name IS NULL \n",
    "  AND start_station_id IS NULL)\n",
    "  OR (end_station_name IS NULL\n",
    "  AND end_station_id IS NULL);\n",
    "```\n",
    "\n",
    "*Percent of NULL values*\n",
    "```sql\n",
    "-- trips_p1\n",
    "SELECT round(100 * \n",
    " (SELECT CAST(COUNT(*) AS numeric) \n",
    "  FROM bike_trips.trips_p1\n",
    "  WHERE (start_station_name IS NULL \n",
    "  AND start_station_id IS NULL)\n",
    "  OR (end_station_name IS NULL\n",
    "  AND end_station_id IS NULL)\n",
    "  ) /\t\n",
    " (SELECT CAST(COUNT(*) AS numeric)\n",
    "  FROM bike_trips.trips_p1)\n",
    "\t\t\t , 2) AS NULL_values_percent\n",
    "\n",
    "-- none\n",
    "```\n",
    "\n",
    "```sql\n",
    "-- trips_p2\n",
    "SELECT round(100 * \n",
    " (SELECT CAST(COUNT(*) AS numeric) \n",
    "  FROM bike_trips.trips_p2\n",
    "  WHERE (start_station_name IS NULL \n",
    "  AND start_station_id IS NULL)\n",
    "  OR (end_station_name IS NULL\n",
    "  AND end_station_id IS NULL)\n",
    "  ) /\t\n",
    " (SELECT CAST(COUNT(*) AS numeric)\n",
    "  FROM bike_trips.trips_p2)\n",
    "\t\t\t , 2) AS NULL_values_percent\n",
    "\n",
    "-- 12.68% of data is NULL\n",
    "```\n",
    "\n",
    "Since only table **trips_p2** has NULL values, we then use the table **trips_p2** as reference.\n",
    "```sql\n",
    "-- entire dataset\n",
    "SELECT round(100 * \n",
    " (SELECT CAST(COUNT(*) AS numeric) \n",
    "  FROM bike_trips.trips_p2\n",
    "  WHERE (start_station_name IS NULL \n",
    "  AND start_station_id IS NULL)\n",
    "  OR (end_station_name IS NULL\n",
    "  AND end_station_id IS NULL)\n",
    "  ) /\t\n",
    " (SELECT CAST(COUNT(*) AS numeric)\n",
    "  FROM bike_trips.trips)\n",
    "\t\t\t , 2) AS omitted_data_percent\n",
    "\n",
    "-- 3.45% of data is NULL\n",
    "```\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<h2 align = \"center\">Stations table</h2>\n",
    "\n",
    "<h3><strong>Cleaning</strong></h3>\n",
    "\n",
    "*Import csv files*\n",
    "\n",
    "- missing_stations.csv\n",
    "\n",
    "Add the missing stations to Stations table\n",
    "\n",
    "```sql\n",
    "-- Import\n",
    "COPY bike_trips.stations (\n",
    "  id, \n",
    "  name, \n",
    "  docks,\n",
    "  in_service, \n",
    "  latitude, \n",
    "  longitude, \n",
    "  coordinate)\n",
    "FROM 'D:/Github/divvy-bikeshare/csv files/stations/missing_stations.csv'\n",
    "DELIMITER ',' CSV HEADER;\n",
    "```\n",
    "\n",
    "- id_changes_stations.csv\n",
    "```sql\n",
    "-- Create table\n",
    "CREATE TABLE bike_trips.id_changes_stations (\n",
    "  name varchar,\n",
    "  id bigint);\n",
    "```\n",
    "```sql\n",
    "-- Import\n",
    "COPY bike_trips.id_changes_stations (name, id)\n",
    "FROM 'D:/Github/divvy-bikeshare/csv files/stations/id_changes_stations.csv'\n",
    "DELIMITER ',' CSV HEADER;\n",
    "```\n",
    "\n",
    "*ID change*\n",
    "\n",
    "```sql\n",
    "UPDATE bike_trips.stations as s\n",
    "SET id = c.new_id\n",
    "FROM bike_trips.id_changes_stations as c\n",
    "WHERE s.name = c.old_name;\n",
    "```\n",
    "\n",
    "-- END Data Wrangling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13.82884,
   "end_time": "2022-07-04T06:53:20.991710",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-04T06:53:07.162870",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
